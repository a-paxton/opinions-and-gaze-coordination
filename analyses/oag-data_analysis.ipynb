{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opinions and Gaze: Data Analysis (Step 3 of 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook contains the data analysis for \n",
    "for \"Seeing the other side: Conflict and controversy \n",
    "increase gaze coordination\" (Paxton, Dale, & Richardson, \n",
    "*in preparation*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the **last of three** notebooks for the \n",
    "\"Opinions and Gaze\" project. This must be run **after** \n",
    "the `oag-data_cleaning.ipynb` and `oag-data_processing.ipynb`\n",
    "files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this file from scratch, you will need:\n",
    "* `data/04-analysis_dataframes`: Directory of analysis- and\n",
    "    plotting-ready dataframes, produced by `oag-data_processing.ipynb`.\n",
    "    * `oag-plotting_df.csv`: Dataframe of real and baseline data.\n",
    "* `supplementary-code/`: Directory of additional functions and global\n",
    "    variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Due to data sensitivity (per the Institutional \n",
    "Review Board of the University of California, Merced), \n",
    "only researchers from ICPSR member institutions may access\n",
    "study data through the approved link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear lag (continuous): `ot1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadratic lag (continuous): `ot2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opinion congruence (factor, contrast-coded):\n",
    "- Agreement: `agree = .5`\n",
    "- Disagreement: `agree = -.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic class (factor, contrast-coded):\n",
    "* Mixed-view: `viewtype = .5`\n",
    "* Dominant-view: `viewtype = -.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type (factor, contrast-coded):\n",
    "* Real data: `data = .5`\n",
    "* Baseline (shuffled) data: `data = -.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Preliminaries](#Preliminaries)\n",
    "    - [Import data and convert factors](#Import-data-and-convert-factors)\n",
    "* [Descriptive statistics](#Descriptive-statistics)\n",
    "    - [Derive listener segment statistics](#Derive-listener-segment-statistics)\n",
    "    - [Derive listener demographic statistics](#Derive-listener-demographic-statistics)\n",
    "* [Plotting](#Plotting)\n",
    "* [Data analysis](#Data-analysis)\n",
    "    - [Plot-level analysis](#Plot-level-analysis)\n",
    "    - [Planned analyses](#Planned-analyses)\n",
    "    - [Exploratory analyses](#Exploratory-analyses)\n",
    "    - [Baseline comparisons](#Baseline-comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written by**: A. Paxton (University of California, Berkeley)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date last modified**: 11 April 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the space\n",
    "rm(list=ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: crqa\n",
      "Loading required package: Matrix\n",
      "Warning message:\n",
      "“package ‘Matrix’ was built under R version 3.3.2”Loading required package: tseriesChaos\n",
      "Loading required package: deSolve\n",
      "Loading required package: fields\n",
      "Warning message:\n",
      "“package ‘fields’ was built under R version 3.3.2”Loading required package: spam\n",
      "Loading required package: grid\n",
      "Spam version 1.4-0 (2016-08-29) is loaded.\n",
      "Type 'help( Spam)' or 'demo( spam)' for a short introduction \n",
      "and overview of this package.\n",
      "Help for individual functions is also obtained by adding the\n",
      "suffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n",
      "\n",
      "Attaching package: ‘spam’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    backsolve, forwardsolve\n",
      "\n",
      "Loading required package: maps\n",
      "Loading required package: plot3D\n",
      "Loading required package: pracma\n",
      "Warning message:\n",
      "“package ‘pracma’ was built under R version 3.3.2”\n",
      "Attaching package: ‘pracma’\n",
      "\n",
      "The following object is masked from ‘package:deSolve’:\n",
      "\n",
      "    rk4\n",
      "\n",
      "The following objects are masked from ‘package:Matrix’:\n",
      "\n",
      "    expm, lu, tril, triu\n",
      "\n",
      "Loading required package: lme4\n",
      "Loading required package: ggplot2\n",
      "Warning message:\n",
      "“package ‘ggplot2’ was built under R version 3.3.2”Loading required package: gsubfn\n",
      "Loading required package: proto\n",
      "Loading required package: zoo\n",
      "Warning message:\n",
      "“package ‘zoo’ was built under R version 3.3.2”\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "Loading required package: plyr\n",
      "\n",
      "Attaching package: ‘plyr’\n",
      "\n",
      "The following object is masked from ‘package:maps’:\n",
      "\n",
      "    ozone\n",
      "\n",
      "Loading required package: dplyr\n",
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 3.3.2”\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:plyr’:\n",
      "\n",
      "    arrange, count, desc, failwith, id, mutate, rename, summarise,\n",
      "    summarize\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Loading required package: data.table\n",
      "\n",
      "Attaching package: ‘data.table’\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "Loading required package: pander\n",
      "Loading required package: scales\n",
      "Warning message:\n",
      "“package ‘scales’ was built under R version 3.3.2”Loading required package: RCurl\n",
      "Warning message:\n",
      "“package ‘RCurl’ was built under R version 3.3.2”Loading required package: bitops\n",
      "Loading required package: stringr\n",
      "Warning message:\n",
      "“package ‘stringr’ was built under R version 3.3.2”Loading required package: LambertW\n",
      "Loading required package: MASS\n",
      "\n",
      "Attaching package: ‘MASS’\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    select\n",
      "\n",
      "This is 'LambertW' version 0.6.4.  Please see the NEWS file and citation(\"LambertW\").\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read in the needed files and functions\n",
    "source('../supplementary-code/libraries_and_functions-oag.r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and convert factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in plotting dataframe\n",
    "plotting_file = file.path(analysis_data_path,\n",
    "                          'oag-plotting_df.csv')\n",
    "plotting_df = read.csv(plotting_file,\n",
    "                       sep=\",\", header=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘bindrcpp’ was built under R version 3.3.2”Warning message:\n",
      "“package ‘lamW’ was built under R version 3.3.2”"
     ]
    }
   ],
   "source": [
    "# create a real-data analysis dataframe\n",
    "analysis_real_df = plotting_df %>%\n",
    "\n",
    "    # filter out baseline\n",
    "    dplyr::filter(data==max(data)) %>%\n",
    "\n",
    "    # reorder agreement for plotting\n",
    "    mutate(agree = factor(agree, levels=c(.5, -.5))) %>%\n",
    "\n",
    "    # factorize everything else\n",
    "    mutate_at(funs(factor), \n",
    "              .vars = factor_variables[!factor_variables %in% c('agree',\n",
    "                                                                'data')]) %>%\n",
    "\n",
    "    # convert recurrence to normal distribution \n",
    "    mutate(r = Gaussianize(r,\n",
    "                           type='s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a real-data plotting dataframe\n",
    "plotting_real_df = plotting_df %>%\n",
    "\n",
    "    # filter out baseline\n",
    "    dplyr::filter(data==max(data)) %>%\n",
    "\n",
    "    # reorder agreement for plotting\n",
    "    mutate(agree = factor(agree, levels=c(.5, -.5))) %>%\n",
    "\n",
    "    # factorize everything else\n",
    "    mutate_at(funs(factor), \n",
    "              .vars = factor_variables[!factor_variables %in% c('agree',\n",
    "                                                                'data')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a baseline-data analysis dataframe\n",
    "analysis_baseline_df = plotting_df %>%\n",
    "\n",
    "    # filter out baseline\n",
    "    dplyr::filter(data==min(data)) %>%\n",
    "\n",
    "    # reorder agreement for plotting\n",
    "    mutate(agree = factor(agree, levels=c(.5, -.5))) %>%\n",
    "\n",
    "    # factorize everything else\n",
    "    mutate_at(funs(factor), \n",
    "              .vars = factor_variables[!factor_variables %in% c('agree',\n",
    "                                                                'data')]) %>%\n",
    "    # convert recurrence to normal distribution \n",
    "    mutate(r = Gaussianize(r,\n",
    "                           type='s')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a baseline-data plotting dataframe\n",
    "plotting_baseline_df = plotting_df %>%\n",
    "\n",
    "    # filter out baseline\n",
    "    dplyr::filter(data==min(data)) %>%\n",
    "\n",
    "    # reorder agreement for plotting\n",
    "    mutate(agree = factor(agree, levels=c(.5, -.5))) %>%\n",
    "\n",
    "    # factorize everything else\n",
    "    mutate_at(funs(factor), \n",
    "              .vars = factor_variables[!factor_variables %in% c('agree',\n",
    "                                                                'data')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factorize the comparison plotting dataframe\n",
    "analysis_joint_df = plotting_df %>%\n",
    "\n",
    "    # reorder agreement for plotting\n",
    "    mutate(agree = factor(agree, levels=c(.5 ,-.5))) %>%\n",
    "\n",
    "    # factorize everything else\n",
    "    mutate_at(funs(factor), \n",
    "              .vars = factor_variables[!factor_variables %in% 'agree']) %>%\n",
    "\n",
    "    # convert recurrence to normal distribution \n",
    "    mutate(r = Gaussianize(r,\n",
    "                           type='s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factorize the comparison plotting dataframe\n",
    "plotting_df = plotting_df %>%\n",
    "    \n",
    "    # reorder agreement for plotting\n",
    "    mutate(agree = factor(agree, levels=c(.5 ,-.5))) %>%\n",
    "\n",
    "    # factorize everything else\n",
    "    mutate_at(funs(factor), \n",
    "              .vars = factor_variables[!factor_variables %in% 'agree'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section produces basic descriptive statistics \n",
    "about individual speakers' segments and about listeners'\n",
    "demographic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive listener segment statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of unique listeners with any recorded data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listeners who successfully had any recorded data \n",
    "will have had a survey saved with their data. We count those\n",
    "files to show how many listeners had any data recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique **gaze files** do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "68"
      ],
      "text/latex": [
       "68"
      ],
      "text/markdown": [
       "68"
      ],
      "text/plain": [
       "[1] 68"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gaze_file_names = list.files('../data/01-input/listener-gaze-raw',\n",
    "                             recursive=FALSE)\n",
    "gaze_participants = str_extract_all(gaze_file_names,\n",
    "                                    '\\\\d{5}')\n",
    "gaze_participants = lapply(gaze_participants, trimws)\n",
    "length(unique(gaze_participants))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique **questionnaire files** do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "68"
      ],
      "text/latex": [
       "68"
      ],
      "text/markdown": [
       "68"
      ],
      "text/plain": [
       "[1] 68"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "questionnaire_file_names = list.files('../data/01-input/listener-responses-raw',\n",
    "                                      recursive=FALSE,\n",
    "                                     pattern='*.tsv')\n",
    "questionnaire_participants = str_extract_all(questionnaire_file_names,\n",
    "                                             '\\\\d{5}')\n",
    "questionnaire_participants = lapply(questionnaire_participants, trimws)\n",
    "length(unique(questionnaire_participants))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many **unique participants with gaze and/or questionnaire\n",
    "files** do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "68"
      ],
      "text/latex": [
       "68"
      ],
      "text/markdown": [
       "68"
      ],
      "text/plain": [
       "[1] 68"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "questions_or_gaze_participants = c(unique(gaze_participants),\n",
    "                                   unique(questionnaire_participants))\n",
    "length(unique(questions_or_gaze_participants))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfiltered listeners and missing data by segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering all listeners with any recorded data (i.e.,\n",
    "any listener with _at least some_ gaze data tracked \n",
    "during _at least one_ of the segments and with _some_\n",
    "included metadata) and all segments with at any recorded\n",
    "data (i.e., no individual listeners' segments in which\n",
    "no samples were recorded):\n",
    "1. how many listeners do we have overall,\n",
    "1. how many listeners do we have per segment, \n",
    "1. and what proportion of data are missing per segment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the missing data table\n",
    "missing_data_filename = file.path(processed_data_path,\n",
    "                                  'listener-missing_data.csv')\n",
    "missing_data = read.table(missing_data_filename,\n",
    "                          sep=',',\n",
    "                          header=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered_listeners = missing_data %>% ungroup() %>%\n",
    "    dplyr::filter(is.na(r_event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered_stats = unfiltered_listeners %>% ungroup() %>%\n",
    "    group_by(topic, side) %>%\n",
    "    summarise(unique_listeners = n(),\n",
    "              proportion_missing = round(mean(proportion),\n",
    "                                        3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>topic</th><th scope=col>side</th><th scope=col>unique_listeners</th><th scope=col>proportion_missing</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>abortion       </td><td>only           </td><td>58             </td><td>0.376          </td></tr>\n",
       "\t<tr><td>death-penalty  </td><td>against        </td><td>58             </td><td>0.356          </td></tr>\n",
       "\t<tr><td>death-penalty  </td><td>for            </td><td>57             </td><td>0.366          </td></tr>\n",
       "\t<tr><td>drinking-age   </td><td>for            </td><td>55             </td><td>0.314          </td></tr>\n",
       "\t<tr><td>gay-marriage   </td><td>only           </td><td>59             </td><td>0.308          </td></tr>\n",
       "\t<tr><td>junk-food-tax  </td><td>against        </td><td>55             </td><td>0.379          </td></tr>\n",
       "\t<tr><td>junk-food-tax  </td><td>for            </td><td>58             </td><td>0.336          </td></tr>\n",
       "\t<tr><td>legal-marijuana</td><td>only           </td><td>58             </td><td>0.357          </td></tr>\n",
       "\t<tr><td>tax-rich       </td><td>only           </td><td>42             </td><td>0.360          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " topic & side & unique\\_listeners & proportion\\_missing\\\\\n",
       "\\hline\n",
       "\t abortion        & only            & 58              & 0.376          \\\\\n",
       "\t death-penalty   & against         & 58              & 0.356          \\\\\n",
       "\t death-penalty   & for             & 57              & 0.366          \\\\\n",
       "\t drinking-age    & for             & 55              & 0.314          \\\\\n",
       "\t gay-marriage    & only            & 59              & 0.308          \\\\\n",
       "\t junk-food-tax   & against         & 55              & 0.379          \\\\\n",
       "\t junk-food-tax   & for             & 58              & 0.336          \\\\\n",
       "\t legal-marijuana & only            & 58              & 0.357          \\\\\n",
       "\t tax-rich        & only            & 42              & 0.360          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "topic | side | unique_listeners | proportion_missing | \n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| abortion        | only            | 58              | 0.376           | \n",
       "| death-penalty   | against         | 58              | 0.356           | \n",
       "| death-penalty   | for             | 57              | 0.366           | \n",
       "| drinking-age    | for             | 55              | 0.314           | \n",
       "| gay-marriage    | only            | 59              | 0.308           | \n",
       "| junk-food-tax   | against         | 55              | 0.379           | \n",
       "| junk-food-tax   | for             | 58              | 0.336           | \n",
       "| legal-marijuana | only            | 58              | 0.357           | \n",
       "| tax-rich        | only            | 42              | 0.360           | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  topic           side    unique_listeners proportion_missing\n",
       "1 abortion        only    58               0.376             \n",
       "2 death-penalty   against 58               0.356             \n",
       "3 death-penalty   for     57               0.366             \n",
       "4 drinking-age    for     55               0.314             \n",
       "5 gay-marriage    only    59               0.308             \n",
       "6 junk-food-tax   against 55               0.379             \n",
       "7 junk-food-tax   for     58               0.336             \n",
       "8 legal-marijuana only    58               0.357             \n",
       "9 tax-rich        only    42               0.360             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unfiltered_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many unique listeners were included in the \n",
    "unfiltered dataset**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "64"
      ],
      "text/latex": [
       "64"
      ],
      "text/markdown": [
       "64"
      ],
      "text/plain": [
       "[1] 64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(unique(unfiltered_listeners$listener))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, **how many listeners were included on each\n",
    " segment in the unfiltered dataset**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "55.56"
      ],
      "text/latex": [
       "55.56"
      ],
      "text/markdown": [
       "55.56"
      ],
      "text/plain": [
       "[1] 55.56"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(unfiltered_stats$unique_listeners),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, **what proportion of the gaze data was \n",
    "missing across the unfiltered dataset**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.35"
      ],
      "text/latex": [
       "0.35"
      ],
      "text/markdown": [
       "0.35"
      ],
      "text/plain": [
       "[1] 0.35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(unfiltered_stats$proportion_missing),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered listeners and missing data by segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering just the listeners that we consider to have\n",
    "usable data for each segment (i.e., no more than 30% \n",
    "missing gaze data in the segment):\n",
    "1. how many listeners do we have overall,\n",
    "1. how many listeners do we have per segment, \n",
    "1. and what proportion of data are missing per segment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_listeners = missing_data %>% ungroup() %>%\n",
    "    dplyr::filter(is.na(r_event) & proportion<=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stats = filtered_listeners %>% ungroup() %>%\n",
    "    group_by(topic, side) %>%\n",
    "    summarise(unique_listeners = n(),\n",
    "              proportion_missing = round(mean(proportion),\n",
    "                                        3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>topic</th><th scope=col>side</th><th scope=col>unique_listeners</th><th scope=col>proportion_missing</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>abortion       </td><td>only           </td><td>31             </td><td>0.166          </td></tr>\n",
       "\t<tr><td>death-penalty  </td><td>against        </td><td>33             </td><td>0.148          </td></tr>\n",
       "\t<tr><td>death-penalty  </td><td>for            </td><td>35             </td><td>0.156          </td></tr>\n",
       "\t<tr><td>drinking-age   </td><td>for            </td><td>35             </td><td>0.132          </td></tr>\n",
       "\t<tr><td>gay-marriage   </td><td>only           </td><td>34             </td><td>0.141          </td></tr>\n",
       "\t<tr><td>junk-food-tax  </td><td>against        </td><td>30             </td><td>0.156          </td></tr>\n",
       "\t<tr><td>junk-food-tax  </td><td>for            </td><td>32             </td><td>0.123          </td></tr>\n",
       "\t<tr><td>legal-marijuana</td><td>only           </td><td>36             </td><td>0.153          </td></tr>\n",
       "\t<tr><td>tax-rich       </td><td>only           </td><td>23             </td><td>0.138          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " topic & side & unique\\_listeners & proportion\\_missing\\\\\n",
       "\\hline\n",
       "\t abortion        & only            & 31              & 0.166          \\\\\n",
       "\t death-penalty   & against         & 33              & 0.148          \\\\\n",
       "\t death-penalty   & for             & 35              & 0.156          \\\\\n",
       "\t drinking-age    & for             & 35              & 0.132          \\\\\n",
       "\t gay-marriage    & only            & 34              & 0.141          \\\\\n",
       "\t junk-food-tax   & against         & 30              & 0.156          \\\\\n",
       "\t junk-food-tax   & for             & 32              & 0.123          \\\\\n",
       "\t legal-marijuana & only            & 36              & 0.153          \\\\\n",
       "\t tax-rich        & only            & 23              & 0.138          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "topic | side | unique_listeners | proportion_missing | \n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| abortion        | only            | 31              | 0.166           | \n",
       "| death-penalty   | against         | 33              | 0.148           | \n",
       "| death-penalty   | for             | 35              | 0.156           | \n",
       "| drinking-age    | for             | 35              | 0.132           | \n",
       "| gay-marriage    | only            | 34              | 0.141           | \n",
       "| junk-food-tax   | against         | 30              | 0.156           | \n",
       "| junk-food-tax   | for             | 32              | 0.123           | \n",
       "| legal-marijuana | only            | 36              | 0.153           | \n",
       "| tax-rich        | only            | 23              | 0.138           | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  topic           side    unique_listeners proportion_missing\n",
       "1 abortion        only    31               0.166             \n",
       "2 death-penalty   against 33               0.148             \n",
       "3 death-penalty   for     35               0.156             \n",
       "4 drinking-age    for     35               0.132             \n",
       "5 gay-marriage    only    34               0.141             \n",
       "6 junk-food-tax   against 30               0.156             \n",
       "7 junk-food-tax   for     32               0.123             \n",
       "8 legal-marijuana only    36               0.153             \n",
       "9 tax-rich        only    23               0.138             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many unique listeners are in the filtered dataset**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "51"
      ],
      "text/latex": [
       "51"
      ],
      "text/markdown": [
       "51"
      ],
      "text/plain": [
       "[1] 51"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(unique(filtered_listeners$listener))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, **how many listeners were included on each\n",
    " segment in the filtered dataset**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "32.11"
      ],
      "text/latex": [
       "32.11"
      ],
      "text/markdown": [
       "32.11"
      ],
      "text/plain": [
       "[1] 32.11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(filtered_stats$unique_listeners),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, **what proportion of the gaze data was \n",
    "missing in the filtered dataset**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.146"
      ],
      "text/latex": [
       "0.146"
      ],
      "text/markdown": [
       "0.146"
      ],
      "text/plain": [
       "[1] 0.146"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(filtered_stats$proportion_missing),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered segments and missing data by listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_segments = filtered_listeners %>% ungroup() %>%\n",
    "    group_by(listener) %>%\n",
    "    summarise(segments = n(),\n",
    "              proportion_missing = mean(proportion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, **how many segments does each listener \n",
    "contribute to the filtered dataset**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5.67"
      ],
      "text/latex": [
       "5.67"
      ],
      "text/markdown": [
       "5.67"
      ],
      "text/plain": [
       "[1] 5.67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(filtered_segments$segments),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, **what proportion of missing data does each listener \n",
    "have for segments included in the filtered dataset**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.169"
      ],
      "text/latex": [
       "0.169"
      ],
      "text/markdown": [
       "0.169"
      ],
      "text/plain": [
       "[1] 0.169"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(filtered_segments$proportion_missing),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discarded listeners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many listeners were discarded because they were\n",
    "**missing required questionnaire or opinion** data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for missing files\n",
    "missing_metadata_participants = data.frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in missing opinion dataframe, if it exists\n",
    "missing_opinion_filename = file.path(processed_data_path,\n",
    "                                     'listener-missing_opinions.csv')\n",
    "if (file.exists(missing_opinion_filename)){\n",
    "\n",
    "    # add reason for missing\n",
    "    missing_opinions = read.table(missing_opinion_filename,\n",
    "                                  sep=\",\",\n",
    "                                  header=TRUE) %>%\n",
    "        mutate(reason = 'missing_opinions')\n",
    "    \n",
    "    # append to dataframe\n",
    "    missing_metadata_participants = rbind.data.frame(missing_metadata_participants,\n",
    "                                                     missing_opinions)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in missing questionnaire dataframe, if it exists\n",
    "missing_questionnaire_filename = file.path(processed_data_path,\n",
    "                                           'listener-missing_questionnaire.csv')\n",
    "if (file.exists(missing_questionnaire_filename)){\n",
    "\n",
    "    # add reason for missing\n",
    "    missing_questionnaire = read.table(missing_questionnaire_filename,\n",
    "                                       sep=\",\",\n",
    "                                       header=TRUE)\n",
    "    \n",
    "    # append to dataframe\n",
    "    missing_metadata_participants = rbind.data.frame(missing_metadata_participants,\n",
    "                                                     missing_questionnaire)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(unique(missing_metadata_participants$listener))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many listeners were completely discarded from the dataset\n",
    "due to having **more than 30% missing data in all trials?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded_listeners = missing_data %>% ungroup() %>%\n",
    "    dplyr::filter(is.na(r_event)) %>%\n",
    "    dplyr::filter(!(listener %in% unique(filtered_segments$listener)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "13"
      ],
      "text/latex": [
       "13"
      ],
      "text/markdown": [
       "13"
      ],
      "text/plain": [
       "[1] 13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(unique(discarded_listeners$listener))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many listeners were discarded due to **other equipment error**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded_participants = c(unique(missing_metadata_participants$listener),\n",
    "                           unique(discarded_listeners$listener))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "recruited_participants = unique(questions_or_gaze_participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_participants = unique(filtered_listeners$listener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(recruited_participants) - \n",
    "    length(discarded_participants) -\n",
    "        length(included_participants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive listener demographic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: All numeric categories were derived alphabetically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“Unknown variables: `topic`, `side`”"
     ]
    }
   ],
   "source": [
    "# read in dataset\n",
    "demographics_data = plotting_real_df %>% ungroup() %>%\n",
    "\n",
    "    # keep only the columns we need\n",
    "    dplyr::select(one_of(crqa_questionnaire_columns),\n",
    "           -topic_and_side,\n",
    "           -agree) %>%\n",
    "\n",
    "    # only one line per participant\n",
    "    distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the self-reported **gender distribution**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Participants were asked about gender but \n",
    "were provided with sex categories.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data = demographics_data %>% ungroup() %>%\n",
    "    group_by(gender) %>%\n",
    "    summarise(gender_counts = n(),\n",
    "              gender_proportion = round((n()/nrow(demographics_data)),\n",
    "                                        3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>gender</th><th scope=col>gender_counts</th><th scope=col>gender_proportion</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.352941176470588</td><td>32                </td><td>0.627             </td></tr>\n",
       "\t<tr><td>0.647058823529412 </td><td>19                </td><td>0.373             </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " gender & gender\\_counts & gender\\_proportion\\\\\n",
       "\\hline\n",
       "\t -0.352941176470588 & 32                 & 0.627             \\\\\n",
       "\t 0.647058823529412  & 19                 & 0.373             \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "gender | gender_counts | gender_proportion | \n",
       "|---|---|\n",
       "| -0.352941176470588 | 32                 | 0.627              | \n",
       "| 0.647058823529412  | 19                 | 0.373              | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  gender             gender_counts gender_proportion\n",
       "1 -0.352941176470588 32            0.627            \n",
       "2 0.647058823529412  19            0.373            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# female = lower, male = higher\n",
    "gender_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the self-reported **mean age**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = demographics_data %>%\n",
    "    dplyr::select(age) %>%\n",
    "    mutate(age = gsub(\"[^0-9.]\", \"\", age)) %>%\n",
    "    dplyr::filter(age != '') %>%\n",
    "    mutate(age = as.numeric(age)) %>%\n",
    "    .$age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "19.84"
      ],
      "text/latex": [
       "19.84"
      ],
      "text/markdown": [
       "19.84"
      ],
      "text/plain": [
       "[1] 19.84"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(age),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the self-reported **native language** distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_lang_data = demographics_data %>% ungroup() %>%\n",
    "\n",
    "    # convert all to lowercase\n",
    "    mutate(native_lang = tolower(native_lang)) %>%\n",
    "    mutate(native_lang = trimws(native_lang)) %>%\n",
    "    \n",
    "    # get counts\n",
    "    group_by(native_lang) %>%\n",
    "    summarise(native_lang_counts = n(),\n",
    "              native_lang_proportion = round(n()/nrow(demographics_data),\n",
    "                                            3)) %>%\n",
    "    ungroup() %>%\n",
    "\n",
    "    # arrange in descending order\n",
    "    dplyr::arrange(native_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>native_lang</th><th scope=col>native_lang_counts</th><th scope=col>native_lang_proportion</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.792387543252595</td><td>19                </td><td>0.373             </td></tr>\n",
       "\t<tr><td>0.207612456747405 </td><td>22                </td><td>0.431             </td></tr>\n",
       "\t<tr><td>1.2076124567474   </td><td>10                </td><td>0.196             </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " native\\_lang & native\\_lang\\_counts & native\\_lang\\_proportion\\\\\n",
       "\\hline\n",
       "\t -0.792387543252595 & 19                 & 0.373             \\\\\n",
       "\t 0.207612456747405  & 22                 & 0.431             \\\\\n",
       "\t 1.2076124567474    & 10                 & 0.196             \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "native_lang | native_lang_counts | native_lang_proportion | \n",
       "|---|---|---|\n",
       "| -0.792387543252595 | 19                 | 0.373              | \n",
       "| 0.207612456747405  | 22                 | 0.431              | \n",
       "| 1.2076124567474    | 10                 | 0.196              | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  native_lang        native_lang_counts native_lang_proportion\n",
       "1 -0.792387543252595 19                 0.373                 \n",
       "2 0.207612456747405  22                 0.431                 \n",
       "3 1.2076124567474    10                 0.196                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# English = lowest, Spanish = middle, other = highest\n",
    "native_lang_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive listener opinion statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“Unknown variables: `topic`, `side`”"
     ]
    }
   ],
   "source": [
    "# read in dataset\n",
    "opinion_data = plotting_real_df %>% ungroup() %>%\n",
    "\n",
    "    # keep only the columns we need\n",
    "    dplyr::select(one_of(crqa_questionnaire_columns),\n",
    "           topic_and_side,\n",
    "          -gender,\n",
    "          -native_lang,\n",
    "          -age) %>%\n",
    "\n",
    "    # get one line per topic and side\n",
    "    distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the **distribution of self-reported agreement** of listeners with the speaker, regardless of topic and side?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "agree_bias = opinion_data %>% ungroup() %>%\n",
    "    group_by(agree) %>%\n",
    "    summarise(agree_counts = n(),\n",
    "              agree_proportions = round(n()/nrow(opinion_data),\n",
    "                                       3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>agree</th><th scope=col>agree_counts</th><th scope=col>agree_proportions</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.5  </td><td>192  </td><td>0.664</td></tr>\n",
       "\t<tr><td>-0.5 </td><td> 97  </td><td>0.336</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " agree & agree\\_counts & agree\\_proportions\\\\\n",
       "\\hline\n",
       "\t 0.5   & 192   & 0.664\\\\\n",
       "\t -0.5  &  97   & 0.336\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "agree | agree_counts | agree_proportions | \n",
       "|---|---|\n",
       "| 0.5   | 192   | 0.664 | \n",
       "| -0.5  |  97   | 0.336 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  agree agree_counts agree_proportions\n",
       "1 0.5   192          0.664            \n",
       "2 -0.5   97          0.336            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# agree = .5, disagree = -.5\n",
    "agree_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of opinion congruence by topic class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for histogram\n",
    "agreement_plots = plotting_df %>% ungroup() %>%\n",
    "\n",
    "    # get just one line per listener per topic\n",
    "    dplyr::select(speaker, listener, topic_and_side, agree, viewtype) %>%\n",
    "    group_by(speaker, listener, topic_and_side, agree, viewtype) %>%\n",
    "    distinct() %>%\n",
    "    ungroup() %>%\n",
    "\n",
    "    # group for counts\n",
    "    group_by(agree, viewtype) %>%\n",
    "    summarise(counts = n()) %>%\n",
    "    ungroup() %>%\n",
    "\n",
    "    # convert counts to proportion\n",
    "    mutate(proportion = counts/sum(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the plot\n",
    "agreement_distribution = ggplot(data=agreement_plots,\n",
    "                                aes(x=as.factor(agree),\n",
    "                                    y=proportion,\n",
    "                                    fill=as.factor(viewtype)),\n",
    "                               labeller = agree_labeller) +\n",
    "    geom_bar(stat=\"identity\",\n",
    "             position='dodge')+\n",
    "    scale_fill_manual(name=\"Opinion congruence\",\n",
    "                      breaks=c(.5,-.5),\n",
    "                      labels=c(\"Agree\", \"Disagree\"),\n",
    "                      values=c(\"#b2182b\", \"#67a9cf\")) +\n",
    "    scale_x_discrete(labels=c(\"Mixed-view\",\"Dominant-view\")) +\n",
    "    theme(legend.position='bottom') +\n",
    "    xlab(\"Topic class\") +\n",
    "    ylab(\"Proportion\") +\n",
    "    ggtitle(\"Listener agreement by topic class\\nand opinion congruence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a high-resolution version\n",
    "ggsave(plot = agreement_distribution,\n",
    "       height = 4,\n",
    "       width = 4,\n",
    "       filename = '../figures/gca-agreement_viewtype_distribution.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a smaller version of the plot\n",
    "ggsave(plot = agreement_distribution,\n",
    "       height = 4,\n",
    "       width = 4,\n",
    "       dpi=100,\n",
    "       filename = '../figures/gca-agreement_viewtype_distribution-inline.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figures/gca-agreement_viewtype_distribution-inline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above breaks down listeners' self-reported\n",
    "agreement (blue) or disagreement (red) with each segment, along\n",
    "with whether that segment was part of a mixed- (right)\n",
    "or dominant-view (left) topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual segment plot for all listeners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do all listeners' individual segments look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all individual listeners\n",
    "all_listener_plot = ggplot(plotting_real_df, \n",
    "                           aes(x=t, \n",
    "                               y=r, \n",
    "                               group=topic_and_side, \n",
    "                               color=as.factor(agree))) + \n",
    "    facet_wrap(~listener) +\n",
    "    geom_path() +\n",
    "    scale_color_manual(name=\"Opinion congruence\",\n",
    "                      labels=c(\"Agree\", \"Disagree\"),\n",
    "                      values=c(\"#67a9cf\", \"#b2182b\")) +\n",
    "    xlab(\"Lag (in 10Hz samples)\") +\n",
    "    ylab(\"Recurrence (rec)\") +\n",
    "    ggtitle(\"Gaze coordination between listeners and speakers\n",
    "by lag and opinion congruence\") +\n",
    "    theme(strip.text.x = element_blank(),\n",
    "          strip.background = element_rect(colour=\"white\", \n",
    "                                          fill=\"white\"),\n",
    "      legend.position='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a high-resolution version\n",
    "ggsave(plot = all_listener_plot,\n",
    "       height = 7,\n",
    "       width = 7,\n",
    "       filename = '../figures/gca-individual_trials.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save an inline display version\n",
    "ggsave(plot = all_listener_plot,\n",
    "       height = 7,\n",
    "       width = 7,\n",
    "       dpi=100,\n",
    "       filename = '../figures/gca-individual_trials-inline.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figures/gca-individual_trials-inline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each panel above presents all usable data from a single\n",
    "listener. Each line is a single diagonal recurrence profile\n",
    "between the listener and the speaker for a single audio\n",
    "segment. Lines are color-coded according to whether the \n",
    "listener rated having agreed with (blue) or disagreed with\n",
    "(red) the speaker after hearing their segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaze coordination by opinion congruence and lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does speaker-listener gaze coordination look when \n",
    "considering listeners' disagreement versus agreement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot recurrence by agreement only\n",
    "r_by_agreement = ggplot(data=plotting_real_df,\n",
    "                        aes(x=t, \n",
    "                            y=r, \n",
    "                            color=agree,\n",
    "                            group=agree)) + \n",
    "    # plot mean DRP curves\n",
    "    geom_smooth(method=\"loess\",\n",
    "                se=TRUE) +\n",
    "\n",
    "    # add in lines for raw means\n",
    "    geom_line(data = plotting_real_df %>%\n",
    "                      group_by(t, agree) %>%\n",
    "                      summarise(r = mean(r)),\n",
    "              aes(x = t,\n",
    "                  y = r,\n",
    "                  color = agree,\n",
    "                  group = agree)) +\n",
    "\n",
    "    # set color by agreement\n",
    "    scale_color_manual(name=\"Opinion congruence\",\n",
    "                       breaks=c(\"1\",\"0\"),\n",
    "                       labels=c(\"Agree\",\"Disagree\"),\n",
    "                       values=c(\"#67a9cf\",\"#b2182b\")) + \n",
    "\n",
    "    # set labels\n",
    "    xlab(\"Lag (in 10Hz samples)\") +\n",
    "    ylab(\"Recurrence (rec)\") +\n",
    "    ggtitle(\"Gaze coordination by lag\n",
    "and opinion congruence\") +\n",
    "    theme(strip.background = element_rect(colour=\"white\", \n",
    "                                          fill=\"white\"),\n",
    "          legend.position='bottom') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a high-resolution version\n",
    "ggsave(plot = r_by_agreement,\n",
    "       height = 5,\n",
    "       width = 4,\n",
    "       filename = '../figures/gca-main_interaction_plot.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save an inline display version\n",
    "ggsave(plot = r_by_agreement,\n",
    "       height = 5,\n",
    "       width = 4,\n",
    "       dpi=100,\n",
    "       filename = '../figures/gca-main_interaction_plot-inline.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figures/gca-main_interaction_plot-inline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows the aggregated diagonal \n",
    "recurrence profile (DRP) for the planned analysis,\n",
    "predicting recurrence (*rec*) with opinion\n",
    "congruence (listener agreement [blue] versus disagreement\n",
    "[red] with the speaker in each segment) and lag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaze coordination by opinion congruence, topic class, and lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does gaze coordination look when considering opinion \n",
    "congruence (agreement versus disagreement) and topic\n",
    "class (dominant- versus mixed-view topics)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot recurrence by agreement and viewtype\n",
    "r_by_agreement_and_viewtype = ggplot(data=plotting_real_df %>%\n",
    "                                         mutate(agree = ifelse(agree==-.5,\n",
    "                                                               \"Disagree\",\n",
    "                                                               \"Agree\")), \n",
    "                                     aes(x=t, \n",
    "                                         y=r, \n",
    "                                         color=viewtype,\n",
    "                                         group=viewtype)) + \n",
    "\n",
    "    # add in lines for raw means\n",
    "    geom_line(data = plotting_real_df %>%\n",
    "                      mutate(agree = ifelse(agree==-.5,\n",
    "                                            \"Disagree\",\n",
    "                                            \"Agree\")) %>%\n",
    "                      group_by(t, agree, viewtype) %>%\n",
    "                      summarise(r = mean(r)),\n",
    "              aes(x = t,\n",
    "                  y = r,\n",
    "                  color = viewtype,\n",
    "                  group = viewtype)) +\n",
    "\n",
    "    # separate by agreement\n",
    "    facet_wrap(~ agree) +\n",
    "\n",
    "    # set color by dominant- versus mixed-view\n",
    "    scale_color_manual(name=\"Topic class\", \n",
    "                       breaks=c(-.5, .5),\n",
    "                       labels=c(\"Dominant-view\", \"Mixed-view\"),\n",
    "                       values=c(\"#d95f02\",\"#7570b3\")) + \n",
    "\n",
    "    # set labels\n",
    "    xlab(\"Lag (in 10Hz samples)\") +\n",
    "    ylab(\"Recurrence (rec)\") +\n",
    "    ggtitle(\"Gaze coordination by lag,\n",
    "opinion congruence, and topic class\") +\n",
    "    theme(strip.background = element_rect(colour=\"white\", \n",
    "                                          fill=\"white\"),\n",
    "          legend.position='bottom') +\n",
    "\n",
    "    # plot mean DRP curves\n",
    "    geom_smooth(method=\"loess\",\n",
    "                se=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a high-resolution version\n",
    "ggsave(plot = r_by_agreement_and_viewtype,\n",
    "       height = 5,\n",
    "       width = 4,\n",
    "       filename = '../figures/gca-exploratory_interaction_plot.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save an inline display version\n",
    "ggsave(plot = r_by_agreement_and_viewtype,\n",
    "       height = 5,\n",
    "       width = 4,\n",
    "       dpi=100,\n",
    "       filename = '../figures/gca-exploratory_interaction_plot-inline.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figures/gca-exploratory_interaction_plot-inline.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows the aggregated diagonal \n",
    "recurrence profile (DRP) for the exploratory analysis,\n",
    "predicting recurrence (*rec*) with opinion\n",
    "congruence (listener agreement [left panel] versus \n",
    "disagreement [right panel] with the speaker in each segment),\n",
    "topic class (dominant-view [orange] or mixed-view [blue]), and lag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot-level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subsets for plot-level metric analysis\n",
    "one_liner = plotting_real_df %>%\n",
    "    dplyr::filter(t==0) %>%\n",
    "\n",
    "    # shift lag to account for window\n",
    "    mutate(maxlag = maxlag-win_size-1)\n",
    "\n",
    "# separate for agreement and disagreement\n",
    "one_liner_agree = one_liner %>%\n",
    "    dplyr::filter(agree==.5)\n",
    "one_liner_disagree = one_liner %>%\n",
    "    dplyr::filter(agree==-.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum recurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is maximum recurrence different from 0? Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  one_liner$maxrec\n",
       "t = 33.312, df = 288, p-value < 0.00000000000000022\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.08479688 0.09544670\n",
       "sample estimates:\n",
       " mean of x \n",
       "0.09012179 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(one_liner$maxrec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the maximum recurrence values for both\n",
    "agreement and disagreement different from 0?\n",
    "Yes for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  one_liner_agree$maxrec\n",
       "t = 27.489, df = 191, p-value < 0.00000000000000022\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.07753789 0.08952539\n",
       "sample estimates:\n",
       " mean of x \n",
       "0.08353164 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(one_liner_agree$maxrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  one_liner_disagree$maxrec\n",
       "t = 20.083, df = 96, p-value < 0.00000000000000022\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.09296928 0.11336314\n",
       "sample estimates:\n",
       "mean of x \n",
       "0.1031662 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(one_liner_disagree$maxrec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does maximum recurrence differ between\n",
    "agreement and disagreement? No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|      &nbsp;       |  Estimate  |  Std..Error  |  t.value  |   p    |  sig  |\n",
      "|:-----------------:|:----------:|:------------:|:---------:|:------:|:-----:|\n",
      "|  **(Intercept)**  |  0.08872   |   0.01339    |   6.623   | 0.0001 |  ***  |\n",
      "|   **agree-0.5**   | -0.001505  |   0.005324   |  -0.2828  |  0.78  |       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.maxrec.agree = lmer(maxrec ~ agree + \n",
    "                       (1 + agree | listener) + \n",
    "                       (1 + agree | topic_and_side), \n",
    "                       data = one_liner)\n",
    "pander_lme(lm.maxrec.agree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the mean maximum recurrence for agreement\n",
    "and for disagreement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Mean maximum recurrence for agreement: 0.084\"\n"
     ]
    }
   ],
   "source": [
    "print(paste0('Mean maximum recurrence for agreement: ', \n",
    "             round(mean(one_liner_agree$maxrec), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Mean maximum recurrence for disagreement: 0.103\"\n"
     ]
    }
   ],
   "source": [
    "print(paste0('Mean maximum recurrence for disagreement: ',\n",
    "             round(mean(one_liner_disagree$maxrec), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is maxlag different from 0 overall? No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  one_liner$maxlag\n",
       "t = 0.33115, df = 288, p-value = 0.7408\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -1.847479  2.594884\n",
       "sample estimates:\n",
       "mean of x \n",
       "0.3737024 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(one_liner$maxlag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is maximum lag for each agreement group different \n",
    "from 0? No for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  one_liner_agree$maxlag\n",
       "t = 0.03414, df = 191, p-value = 0.9728\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -2.661337  2.755087\n",
       "sample estimates:\n",
       "mean of x \n",
       " 0.046875 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(one_liner_agree$maxlag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  one_liner_disagree$maxlag\n",
       "t = 0.51336, df = 96, p-value = 0.6089\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -2.925723  4.966960\n",
       "sample estimates:\n",
       "mean of x \n",
       " 1.020619 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(one_liner_disagree$maxlag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does maximum lag differ by agreement or disagreement?\n",
    "No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|      &nbsp;       |  Estimate  |  Std..Error  |  t.value  |  p   |  sig  |\n",
      "|:-----------------:|:----------:|:------------:|:---------:|:----:|:-----:|\n",
      "|  **(Intercept)**  |  0.06094   |    1.426     |  0.04273  | 0.97 |       |\n",
      "|   **agree-0.5**   |   0.7486   |    2.394     |  0.3127   | 0.75 |       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.maxlag.agree = lmer(maxlag ~ agree + \n",
    "                       (1 + agree | listener) + \n",
    "                       (1 | topic_and_side), \n",
    "                       data = one_liner)\n",
    "pander_lme(lm.maxlag.agree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the mean maximum lag for agreement and\n",
    "for disagreement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Mean maximum lag for agreement: 0.05 samples (0 sec)\"\n"
     ]
    }
   ],
   "source": [
    "print(paste0('Mean maximum lag for agreement: ',\n",
    "             round(mean(one_liner_agree$maxlag), 2),\n",
    "             ' samples (',\n",
    "             round(mean(one_liner_agree$maxlag)/10, 2),\n",
    "             ' sec)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Mean maximum lag for disagreement: 1.02 samples (0.1 sec)\"\n"
     ]
    }
   ],
   "source": [
    "print(paste0('Mean maximum lag for disagreement: ',\n",
    "             round(mean(one_liner_disagree$maxlag), 2),\n",
    "             ' samples (',\n",
    "             round(mean(one_liner_disagree$maxlag)/10, 2),\n",
    "             ' sec)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planned analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll test the relations among recurrence (`r`), \n",
    "linear lag (`ot1`), quadratic lag (`ot2`), and opinion congruence\n",
    "(`agree`) that we had anticipated testing at the outset of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-way interaction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll model the data using all main terms and up\n",
    "to two-way interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "planned_model_twowayint = lmer(r ~ ot1 + ot2 + agree +\n",
    "                               ot1:agree + ot2:agree + ot1:ot2 +\n",
    "                               (1 + ot1 + ot2 + agree | listener) + \n",
    "                               (1 + ot1 + ot2 + agree | topic_and_side), \n",
    "                               data=analysis_real_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|       &nbsp;        |  Estimate  |  Std..Error  |  t.value  |   p    |  sig  |\n",
      "|:-------------------:|:----------:|:------------:|:---------:|:------:|:-----:|\n",
      "|   **(Intercept)**   |  0.06542   |   0.01323    |   4.946   | 0.0001 |  ***  |\n",
      "|       **ot1**       | -0.004661  |   0.00855    |  -0.5452  |  0.59  |       |\n",
      "|       **ot2**       | -0.001987  |   0.006938   |  -0.2864  |  0.78  |       |\n",
      "|    **agree-0.5**    |  -0.01107  |   0.004569   |  -2.422   | 0.015  |   *   |\n",
      "|  **ot1:agree-0.5**  |  0.004621  |   0.002023   |   2.284   | 0.022  |   *   |\n",
      "|  **ot2:agree-0.5**  |  0.005464  |   0.001999   |   2.733   | 0.006  |  **   |\n",
      "|     **ot1:ot2**     | 0.0009637  |   0.007659   |  0.1258   |  0.9   |       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pander_lme(planned_model_twowayint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full interaction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's include the main terms and all possible \n",
    "interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "planned_model_allint = lmer(r ~ ot1 * ot2 * agree +\n",
    "                            (1 + ot1 + ot2 + agree | listener) + \n",
    "                            (1 + ot1 + ot2 + agree | topic_and_side), \n",
    "                            data=analysis_real_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|         &nbsp;          |  Estimate  |  Std..Error  |  t.value  |   p    |  sig  |\n",
      "|:-----------------------:|:----------:|:------------:|:---------:|:------:|:-----:|\n",
      "|     **(Intercept)**     |  0.07311   |   0.01386    |   5.276   | 0.0001 |  ***  |\n",
      "|         **ot1**         |  -0.01449  |   0.01005    |  -1.442   | 0.149  |       |\n",
      "|         **ot2**         | -0.009901  |   0.008139   |  -1.217   | 0.224  |       |\n",
      "|      **agree-0.5**      |  -0.03397  |   0.01314    |  -2.586   |  0.01  |   *   |\n",
      "|       **ot1:ot2**       |  0.01109   |   0.009396   |   1.18    | 0.238  |       |\n",
      "|    **ot1:agree-0.5**    |  0.03391   |   0.01588    |   2.135   | 0.033  |   *   |\n",
      "|    **ot2:agree-0.5**    |  0.02904   |   0.01284    |   2.262   | 0.024  |   *   |\n",
      "|  **ot1:ot2:agree-0.5**  |  -0.03016  |   0.01622    |   -1.86   | 0.063  |   .   |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pander_lme(planned_model_allint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model better accounts for the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "refitting model(s) with ML (instead of REML)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Df</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>logLik</th><th scope=col>deviance</th><th scope=col>Chisq</th><th scope=col>Chi Df</th><th scope=col>Pr(&gt;Chisq)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>planned_model_twowayint</th><td>28        </td><td>-98119.01 </td><td>-97901.24 </td><td>49087.50  </td><td>-98175.01 </td><td>      NA  </td><td>NA        </td><td>        NA</td></tr>\n",
       "\t<tr><th scope=row>planned_model_allint</th><td>29        </td><td>-98120.46 </td><td>-97894.92 </td><td>49089.23  </td><td>-98178.46 </td><td>3.458249  </td><td> 1        </td><td>0.06293694</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       "  & Df & AIC & BIC & logLik & deviance & Chisq & Chi Df & Pr(>Chisq)\\\\\n",
       "\\hline\n",
       "\tplanned\\_model\\_twowayint & 28         & -98119.01  & -97901.24  & 49087.50   & -98175.01  &       NA   & NA         &         NA\\\\\n",
       "\tplanned\\_model\\_allint & 29         & -98120.46  & -97894.92  & 49089.23   & -98178.46  & 3.458249   &  1         & 0.06293694\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Df | AIC | BIC | logLik | deviance | Chisq | Chi Df | Pr(>Chisq) | \n",
       "|---|---|\n",
       "| planned_model_twowayint | 28         | -98119.01  | -97901.24  | 49087.50   | -98175.01  |       NA   | NA         |         NA | \n",
       "| planned_model_allint | 29         | -98120.46  | -97894.92  | 49089.23   | -98178.46  | 3.458249   |  1         | 0.06293694 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                        Df AIC       BIC       logLik   deviance  Chisq   \n",
       "planned_model_twowayint 28 -98119.01 -97901.24 49087.50 -98175.01       NA\n",
       "planned_model_allint    29 -98120.46 -97894.92 49089.23 -98178.46 3.458249\n",
       "                        Chi Df Pr(>Chisq)\n",
       "planned_model_twowayint NA             NA\n",
       "planned_model_allint     1     0.06293694"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anova(planned_model_twowayint,\n",
    "      planned_model_allint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with all possible interaction terms trends toward\n",
    "but does not significantly perform better than the model\n",
    "with only two-way interaction terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll look into the relations among recurrence (`r`), \n",
    "linear lag (`ot1`), quadratic lag (`ot2`), opinion congruence\n",
    "(`agree`), and topic class (`viewtype`) -- a new variable \n",
    "that we had not expected to explore at the outset of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-way interaction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll model the data using all main terms and up\n",
    "to two-way interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_model_twowayint = lmer(r ~ ot1 + ot2 + agree + viewtype +\n",
    "                                   ot1:agree + ot2:agree +\n",
    "                                   ot1:viewtype + ot2:viewtype +\n",
    "                                   agree:viewtype + ot1:ot2 +\n",
    "                                   (1 + ot1 + ot2 + agree + viewtype | listener) + \n",
    "                                   (1 + ot1 + ot2 + agree + viewtype | topic_and_side), \n",
    "                                   data=analysis_real_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|           &nbsp;            |  Estimate  |  Std..Error  |  t.value  |   p   |  sig  |\n",
      "|:---------------------------:|:----------:|:------------:|:---------:|:-----:|:-----:|\n",
      "|       **(Intercept)**       |  0.04945   |   0.02003    |   2.469   | 0.014 |   *   |\n",
      "|           **ot1**           | -0.002962  |   0.008594   |  -0.3447  | 0.73  |       |\n",
      "|           **ot2**           |  0.003951  |   0.007004   |   0.564   | 0.57  |       |\n",
      "|        **agree-0.5**        |  -0.01357  |   0.006366   |  -2.131   | 0.033 |   *   |\n",
      "|       **viewtype0.5**       |   0.0302   |   0.02898    |   1.042   |  0.3  |       |\n",
      "|      **ot1:agree-0.5**      |  0.005014  |   0.001901   |   2.637   | 0.008 |  **   |\n",
      "|      **ot2:agree-0.5**      |  0.005575  |   0.001867   |   2.987   | 0.003 |  **   |\n",
      "|     **ot1:viewtype0.5**     |  -0.00354  |   0.004668   |  -0.7585  | 0.45  |       |\n",
      "|     **ot2:viewtype0.5**     |  -0.01081  |   0.004956   |  -2.181   | 0.029 |   *   |\n",
      "|  **agree-0.5:viewtype0.5**  | -0.0001536 |   0.007409   | -0.02074  | 0.98  |       |\n",
      "|         **ot1:ot2**         | 0.0009637  |   0.007211   |  0.1337   | 0.89  |       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pander_lme(exploratory_model_twowayint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full interaction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's include the main terms and all possible interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_model_allint = lmer(r ~ ot1 * ot2 * agree * viewtype +\n",
    "                                (1 + ot1 + ot2 + agree + viewtype | listener) + \n",
    "                                (1 + ot1 + ot2 + agree + viewtype | topic_and_side), \n",
    "                                data=analysis_real_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|               &nbsp;                |  Estimate  |  Std..Error  |  t.value  |   p    |  sig  |\n",
      "|:-----------------------------------:|:----------:|:------------:|:---------:|:------:|:-----:|\n",
      "|           **(Intercept)**           |  0.03278   |   0.02234    |   1.467   | 0.142  |       |\n",
      "|               **ot1**               |  0.01771   |   0.01321    |   1.341   |  0.18  |       |\n",
      "|               **ot2**               |   0.0199   |    0.0107    |   1.861   | 0.063  |   .   |\n",
      "|            **agree-0.5**            | -0.009714  |   0.02094    |  -0.4638  |  0.64  |       |\n",
      "|           **viewtype0.5**           |  0.07826   |   0.03396    |   2.305   | 0.021  |   *   |\n",
      "|             **ot1:ot2**             |  -0.01869  |   0.01257    |  -1.487   | 0.137  |       |\n",
      "|          **ot1:agree-0.5**          |  0.002696  |   0.02545    |  0.1059   |  0.92  |       |\n",
      "|          **ot2:agree-0.5**          |  0.00655   |   0.02056    |  0.3186   |  0.75  |       |\n",
      "|         **ot1:viewtype0.5**         |  -0.06379  |   0.01785    |  -3.573   | 0.0004 |  ***  |\n",
      "|         **ot2:viewtype0.5**         |  -0.05801  |   0.01475    |  -3.933   | 0.0001 |  ***  |\n",
      "|      **agree-0.5:viewtype0.5**      |  -0.05173  |    0.0261    |  -1.981   | 0.048  |   *   |\n",
      "|        **ot1:ot2:agree-0.5**        | -0.004327  |   0.02599    |  -0.1665  |  0.87  |       |\n",
      "|       **ot1:ot2:viewtype0.5**       |  0.05893   |   0.01768    |   3.332   | 0.001  |  **   |\n",
      "|    **ot1:agree-0.5:viewtype0.5**    |  0.06189   |   0.03174    |   1.95    | 0.051  |   .   |\n",
      "|    **ot2:agree-0.5:viewtype0.5**    |  0.04541   |   0.02565    |   1.77    | 0.077  |   .   |\n",
      "|  **ot1:ot2:agree-0.5:viewtype0.5**  |  -0.05331  |   0.03242    |  -1.644   |  0.1   |       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pander_lme(exploratory_model_allint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model better accounts for the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "refitting model(s) with ML (instead of REML)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Df</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>logLik</th><th scope=col>deviance</th><th scope=col>Chisq</th><th scope=col>Chi Df</th><th scope=col>Pr(&gt;Chisq)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>exploratory_model_twowayint</th><td>42        </td><td>-100049   </td><td>-99722.38 </td><td>50066.51  </td><td>-100133   </td><td>      NA  </td><td>NA        </td><td>        NA</td></tr>\n",
       "\t<tr><th scope=row>exploratory_model_allint</th><td>47        </td><td>-100061   </td><td>-99695.49 </td><td>50077.51  </td><td>-100155   </td><td>21.99167  </td><td> 5        </td><td>0.00052551</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       "  & Df & AIC & BIC & logLik & deviance & Chisq & Chi Df & Pr(>Chisq)\\\\\n",
       "\\hline\n",
       "\texploratory\\_model\\_twowayint & 42         & -100049    & -99722.38  & 50066.51   & -100133    &       NA   & NA         &         NA\\\\\n",
       "\texploratory\\_model\\_allint & 47         & -100061    & -99695.49  & 50077.51   & -100155    & 21.99167   &  5         & 0.00052551\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Df | AIC | BIC | logLik | deviance | Chisq | Chi Df | Pr(>Chisq) | \n",
       "|---|---|\n",
       "| exploratory_model_twowayint | 42         | -100049    | -99722.38  | 50066.51   | -100133    |       NA   | NA         |         NA | \n",
       "| exploratory_model_allint | 47         | -100061    | -99695.49  | 50077.51   | -100155    | 21.99167   |  5         | 0.00052551 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                            Df AIC     BIC       logLik   deviance Chisq   \n",
       "exploratory_model_twowayint 42 -100049 -99722.38 50066.51 -100133        NA\n",
       "exploratory_model_allint    47 -100061 -99695.49 50077.51 -100155  21.99167\n",
       "                            Chi Df Pr(>Chisq)\n",
       "exploratory_model_twowayint NA             NA\n",
       "exploratory_model_allint     5     0.00052551"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anova(exploratory_model_twowayint,\n",
    "      exploratory_model_allint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the full model accounts for the data\n",
    "significantly better than the model that \n",
    "includes only limited interaction terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-hoc analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the possible differences by opinion congruence and \n",
    "topic class, let's dig a bit more deeply into the exploratory\n",
    "model. What's actually driving the significant effects that\n",
    "we see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataframes by type\n",
    "topic_dfs = split(analysis_real_df,\n",
    "                  analysis_real_df$viewtype)\n",
    "dominant_df = topic_dfs$`-0.5`\n",
    "mixed_df = topic_dfs$`0.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dominant-view model** (`viewtype = -.5`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_model_dominant = lmer(r ~ ot1 * ot2 * agree +\n",
    "                                (1 + ot1 + ot2 + agree | listener) + \n",
    "                                (1 + ot1 + ot2 + agree | topic_and_side), \n",
    "                                data=dominant_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|         &nbsp;          |  Estimate  |  Std..Error  |  t.value  |   p   |  sig  |\n",
      "|:-----------------------:|:----------:|:------------:|:---------:|:-----:|:-----:|\n",
      "|     **(Intercept)**     |  0.03087   |   0.01832    |   1.685   | 0.092 |   .   |\n",
      "|         **ot1**         |  0.01989   |   0.01306    |   1.523   | 0.128 |       |\n",
      "|         **ot2**         |  0.01926   |   0.01176    |   1.638   | 0.101 |       |\n",
      "|      **agree-0.5**      |  -0.00482  |   0.02018    |  -0.2388  | 0.81  |       |\n",
      "|       **ot1:ot2**       |  -0.01869  |   0.01219    |  -1.533   | 0.125 |       |\n",
      "|    **ot1:agree-0.5**    | 0.0004748  |   0.02471    |  0.01922  | 0.98  |       |\n",
      "|    **ot2:agree-0.5**    |  0.01001   |   0.01998    |  0.5006   | 0.62  |       |\n",
      "|  **ot1:ot2:agree-0.5**  | -0.004327  |   0.02521    |  -0.1717  | 0.86  |       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pander_lme(exploratory_model_dominant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find no significant effects for dominant-view topics based on\n",
    "listener agreement or disagreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mixed-view model** (`viewtype = .5`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_model_mixed = lmer(r ~ ot1 * ot2 * agree +\n",
    "                                (1 + ot1 + ot2 + agree | listener) + \n",
    "                                (1 + ot1 + ot2 + agree | topic_and_side), \n",
    "                                data=mixed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|         &nbsp;          |  Estimate  |  Std..Error  |  t.value  |   p    |  sig  |\n",
      "|:-----------------------:|:----------:|:------------:|:---------:|:------:|:-----:|\n",
      "|     **(Intercept)**     |   0.1128   |   0.01859    |   6.068   | 0.0001 |  ***  |\n",
      "|         **ot1**         |  -0.04638  |   0.01318    |  -3.519   | 0.0004 |  ***  |\n",
      "|         **ot2**         |  -0.03933  |   0.009552   |  -4.118   | 0.0001 |  ***  |\n",
      "|      **agree-0.5**      |  -0.06297  |   0.01538    |  -4.094   | 0.0001 |  ***  |\n",
      "|       **ot1:ot2**       |  0.04025   |   0.01173    |   3.431   | 0.001  |  **   |\n",
      "|    **ot1:agree-0.5**    |  0.06565   |   0.01791    |   3.667   | 0.0002 |  ***  |\n",
      "|    **ot2:agree-0.5**    |  0.05119   |   0.01446    |   3.54    | 0.0004 |  ***  |\n",
      "|  **ot1:ot2:agree-0.5**  |  -0.05764  |   0.01827    |  -3.154   | 0.002  |  **   |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pander_lme(exploratory_model_mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mixed-view topics appear to be doing the majority of the heavy\n",
    "lifting with these data: All effects here are significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a term to account for real (`data=.5`) versus baseline \n",
    "data (`data=-.5`) to the planned and exploratory models reported\n",
    "above. In each, we'll again compare models that include only \n",
    "up to two-way interactions with those that include all \n",
    "possible interaction terms to see which better account for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planned analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-way interaction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "planned_model_baseline_twowayint = lmer(r ~ ot1 + ot2 + agree + data +\n",
    "                                        ot1:agree + ot2:agree + \n",
    "                                        ot1:data + ot2:data + \n",
    "                                        agree:data + ot1:ot2 +\n",
    "                                        (1 + agree | listener) + \n",
    "                                        (1 | topic_and_side), \n",
    "                                        data=analysis_joint_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|         &nbsp;          |  Estimate  |  Std..Error  |  t.value  |   p    |  sig  |\n",
      "|:-----------------------:|:----------:|:------------:|:---------:|:------:|:-----:|\n",
      "|     **(Intercept)**     |  0.06424   |   0.01197    |   5.367   | 0.0001 |  ***  |\n",
      "|         **ot1**         | -0.003331  |   0.001919   |  -1.736   | 0.083  |   .   |\n",
      "|         **ot2**         | -0.002774  |   0.001554   |  -1.785   | 0.074  |   .   |\n",
      "|      **agree-0.5**      | -0.0003169 |   0.001872   |  -0.1693  |  0.87  |       |\n",
      "|       **data0.5**       | 0.0003562  |  0.0008942   |  0.3983   |  0.69  |       |\n",
      "|    **ot1:agree-0.5**    | -0.0008192 |  0.0004651   |  -1.761   | 0.078  |   .   |\n",
      "|    **ot2:agree-0.5**    |  0.001456  |  0.0004651   |   3.131   | 0.002  |  **   |\n",
      "|     **ot1:data0.5**     | -0.000742  |  0.0007639   |  -0.9713  |  0.33  |       |\n",
      "|     **ot2:data0.5**     | -0.0003869 |  0.0007639   |  -0.5065  |  0.61  |       |\n",
      "|  **agree-0.5:data0.5**  | -0.0004536 |  0.0002071   |   -2.19   | 0.028  |   *   |\n",
      "|       **ot1:ot2**       |  0.002661  |   0.001955   |   1.361   | 0.173  |       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pander_lme(planned_model_baseline_twowayint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full interaction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "planned_model_baseline_allint = lmer(r ~ ot1 * ot2 * agree * data +\n",
    "                                     (1 + agree | listener) + \n",
    "                                     (1 | topic_and_side), \n",
    "                                     data=analysis_joint_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|             &nbsp;              |  Estimate  |  Std..Error  |  t.value  |   p    |  sig  |\n",
      "|:-------------------------------:|:----------:|:------------:|:---------:|:------:|:-----:|\n",
      "|         **(Intercept)**         |  0.06473   |   0.01203    |   5.381   | 0.0001 |  ***  |\n",
      "|             **ot1**             | -0.004067  |   0.00246    |  -1.654   | 0.098  |   .   |\n",
      "|             **ot2**             | -0.003422  |   0.001987   |  -1.722   | 0.085  |   .   |\n",
      "|          **agree-0.5**          | -0.001308  |   0.003795   |  -0.3447  |  0.73  |       |\n",
      "|           **data0.5**           |  0.008107  |   0.006429   |   1.261   | 0.207  |       |\n",
      "|           **ot1:ot2**           |  0.003625  |   0.002515   |   1.441   |  0.15  |       |\n",
      "|        **ot1:agree-0.5**        | 0.0007918  |   0.004245   |  0.1865   |  0.85  |       |\n",
      "|        **ot2:agree-0.5**        |  0.002921  |   0.00343    |  0.8516   |  0.39  |       |\n",
      "|         **ot1:data0.5**         | -0.009389  |   0.008157   |  -1.151   |  0.25  |       |\n",
      "|         **ot2:data0.5**         | -0.006728  |   0.00659    |  -1.021   |  0.31  |       |\n",
      "|      **agree-0.5:data0.5**      |  -0.02853  |    0.0111    |  -2.571   |  0.01  |   *   |\n",
      "|      **ot1:ot2:agree-0.5**      | -0.002274  |   0.004342   |  -0.5236  |  0.6   |       |\n",
      "|       **ot1:ot2:data0.5**       |  0.006633  |   0.008343   |   0.795   |  0.43  |       |\n",
      "|    **ot1:agree-0.5:data0.5**    |  0.03214   |   0.01408    |   2.283   | 0.022  |   *   |\n",
      "|    **ot2:agree-0.5:data0.5**    |  0.02403   |   0.01137    |   2.113   | 0.035  |   *   |\n",
      "|  **ot1:ot2:agree-0.5:data0.5**  |  -0.02633  |    0.0144    |  -1.829   | 0.068  |   .   |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pander_lme(planned_model_baseline_allint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "refitting model(s) with ML (instead of REML)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Df</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>logLik</th><th scope=col>deviance</th><th scope=col>Chisq</th><th scope=col>Chi Df</th><th scope=col>Pr(&gt;Chisq)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>planned_model_baseline_twowayint</th><td>16          </td><td>-1152108    </td><td>-1151945    </td><td>576069.8    </td><td>-1152140    </td><td>      NA    </td><td>NA          </td><td>          NA</td></tr>\n",
       "\t<tr><th scope=row>planned_model_baseline_allint</th><td>21          </td><td>-1152123    </td><td>-1151910    </td><td>576082.7    </td><td>-1152165    </td><td>25.73546    </td><td> 5          </td><td>0.0001004188</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       "  & Df & AIC & BIC & logLik & deviance & Chisq & Chi Df & Pr(>Chisq)\\\\\n",
       "\\hline\n",
       "\tplanned\\_model\\_baseline\\_twowayint & 16           & -1152108     & -1151945     & 576069.8     & -1152140     &       NA     & NA           &           NA\\\\\n",
       "\tplanned\\_model\\_baseline\\_allint & 21           & -1152123     & -1151910     & 576082.7     & -1152165     & 25.73546     &  5           & 0.0001004188\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Df | AIC | BIC | logLik | deviance | Chisq | Chi Df | Pr(>Chisq) | \n",
       "|---|---|\n",
       "| planned_model_baseline_twowayint | 16           | -1152108     | -1151945     | 576069.8     | -1152140     |       NA     | NA           |           NA | \n",
       "| planned_model_baseline_allint | 21           | -1152123     | -1151910     | 576082.7     | -1152165     | 25.73546     |  5           | 0.0001004188 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                                 Df AIC      BIC      logLik   deviance\n",
       "planned_model_baseline_twowayint 16 -1152108 -1151945 576069.8 -1152140\n",
       "planned_model_baseline_allint    21 -1152123 -1151910 576082.7 -1152165\n",
       "                                 Chisq    Chi Df Pr(>Chisq)  \n",
       "planned_model_baseline_twowayint       NA NA               NA\n",
       "planned_model_baseline_allint    25.73546  5     0.0001004188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anova(planned_model_baseline_twowayint,\n",
    "      planned_model_baseline_allint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're significantly better able to maximize log-likelihood \n",
    "of the model by including all possible interaction terms, \n",
    "rather than just including two-way interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-way interaction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_model_baseline_twowayint = lmer(r ~ ot1 + ot2 + agree + viewtype + data +\n",
    "                                            ot1:agree + ot2:agree + \n",
    "                                            ot1:viewtype + ot2:viewtype +\n",
    "                                            ot1:ot2 + agree:viewtype +\n",
    "                                            ot1:data + ot2:data + \n",
    "                                            viewtype:data + agree:data +\n",
    "                                            (1 + data | listener) + \n",
    "                                            (1 + data | topic_and_side), \n",
    "                                            data=analysis_joint_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|           &nbsp;            |   Estimate   |  Std..Error  |  t.value  |   p    |  sig  |\n",
      "|:---------------------------:|:------------:|:------------:|:---------:|:------:|:-----:|\n",
      "|       **(Intercept)**       |   0.05171    |   0.01845    |   2.802   | 0.005  |  **   |\n",
      "|           **ot1**           |  -0.001227   |   0.002058   |  -0.5965  |  0.55  |       |\n",
      "|           **ot2**           |  -0.002773   |   0.001672   |  -1.658   | 0.097  |   .   |\n",
      "|        **agree-0.5**        |   0.002929   |  0.0005975   |   4.903   | 0.0001 |  ***  |\n",
      "|       **viewtype0.5**       |   0.02221    |   0.02462    |  0.9023   |  0.37  |       |\n",
      "|         **data0.5**         |  0.0005654   |   0.001481   |  0.3817   |  0.7   |       |\n",
      "|      **ot1:agree-0.5**      | -0.000003684 |  0.0005041   | -0.007308 |  0.99  |       |\n",
      "|      **ot2:agree-0.5**      |   0.001457   |  0.0005041   |   2.89    | 0.004  |  **   |\n",
      "|     **ot1:viewtype0.5**     |  -0.004165   |  0.0004809   |   -8.66   | 0.0001 |  ***  |\n",
      "|     **ot2:viewtype0.5**     | -0.000002103 |  0.0004809   | -0.004372 |   1    |       |\n",
      "|         **ot1:ot2**         |   0.002661   |   0.002082   |   1.278   | 0.201  |       |\n",
      "|  **agree-0.5:viewtype0.5**  |  -0.005893   |  0.0001508   |  -39.08   | 0.0001 |  ***  |\n",
      "|       **ot1:data0.5**       |  -0.000742   |  0.0008134   |  -0.9122  |  0.36  |       |\n",
      "|       **ot2:data0.5**       |  -0.0003869  |  0.0008134   |  -0.4757  |  0.63  |       |\n",
      "|   **viewtype0.5:data0.5**   |  -0.0007071  |   0.001255   |  -0.5634  |  0.57  |       |\n",
      "|    **agree-0.5:data0.5**    |  -0.0009388  |  0.0002486   |  -3.777   | 0.0002 |  ***  |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pander_lme(exploratory_model_baseline_twowayint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full interaction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_model_baseline_allint = lmer(r ~ ot1 * ot2 * agree * viewtype * data +\n",
    "                                         (1 + data | listener) + \n",
    "                                         (1 + data | topic_and_side), \n",
    "                                         data=analysis_joint_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|                   &nbsp;                    |  Estimate   |  Std..Error  |  t.value  |   p    |  sig  |\n",
      "|:-------------------------------------------:|:-----------:|:------------:|:---------:|:------:|:-----:|\n",
      "|               **(Intercept)**               |   0.05214   |   0.01861    |   2.802   | 0.005  |  **   |\n",
      "|                   **ot1**                   |  -0.000602  |   0.003722   |  -0.1617  |  0.87  |       |\n",
      "|                   **ot2**                   |  -0.003444  |   0.003007   |  -1.145   |  0.25  |       |\n",
      "|                **agree-0.5**                | -0.0004907  |   0.006066   | -0.08089  |  0.94  |       |\n",
      "|               **viewtype0.5**               |   0.02233   |   0.02495    |  0.8951   |  0.37  |       |\n",
      "|                 **data0.5**                 |  -0.02251   |   0.009794   |  -2.299   | 0.022  |   *   |\n",
      "|                 **ot1:ot2**                 |  0.002148   |   0.003807   |  0.5643   |  0.57  |       |\n",
      "|              **ot1:agree-0.5**              |  0.002184   |   0.007697   |  0.2837   |  0.78  |       |\n",
      "|              **ot2:agree-0.5**              |  0.005838   |   0.006218   |   0.939   |  0.35  |       |\n",
      "|             **ot1:viewtype0.5**             |  -0.006858  |   0.005237   |   -1.31   |  0.19  |       |\n",
      "|             **ot2:viewtype0.5**             | 0.00004257  |   0.00423    |  0.01006  |  0.99  |       |\n",
      "|          **agree-0.5:viewtype0.5**          |  -0.002462  |   0.007567   |  -0.3253  |  0.74  |       |\n",
      "|               **ot1:data0.5**               |   0.02155   |   0.01234    |   1.746   | 0.081  |   .   |\n",
      "|               **ot2:data0.5**               |   0.0241    |   0.009973   |   2.416   | 0.016  |   *   |\n",
      "|            **agree-0.5:data0.5**            |  -0.001569  |   0.02012    | -0.07797  |  0.94  |       |\n",
      "|           **viewtype0.5:data0.5**           |   0.06032   |   0.01374    |   4.389   | 0.0001 |  ***  |\n",
      "|            **ot1:ot2:agree-0.5**            |  -0.003022  |   0.007872   |  -0.3839  |  0.7   |       |\n",
      "|           **ot1:ot2:viewtype0.5**           |  0.002923   |   0.005356   |  0.5458   |  0.58  |       |\n",
      "|        **ot1:agree-0.5:viewtype0.5**        | -0.00006966 |    0.0096    | -0.007257 |  0.99  |       |\n",
      "|        **ot2:agree-0.5:viewtype0.5**        |  -0.004174  |   0.007755   |  -0.5382  |  0.59  |       |\n",
      "|             **ot1:ot2:data0.5**             |   -0.0228   |   0.01263    |  -1.806   | 0.071  |   .   |\n",
      "|          **ot1:agree-0.5:data0.5**          |  0.0007993  |   0.02553    |  0.03131  |  0.98  |       |\n",
      "|          **ot2:agree-0.5:data0.5**          | -0.0009268  |   0.02062    | -0.04494  |  0.96  |       |\n",
      "|         **ot1:viewtype0.5:data0.5**         |  -0.06124   |   0.01737    |  -3.526   | 0.0004 |  ***  |\n",
      "|         **ot2:viewtype0.5:data0.5**         |  -0.06102   |   0.01403    |  -4.349   | 0.0001 |  ***  |\n",
      "|      **agree-0.5:viewtype0.5:data0.5**      |  -0.05621   |    0.0251    |   -2.24   | 0.025  |   *   |\n",
      "|      **ot1:ot2:agree-0.5:viewtype0.5**      |  0.0002509  |   0.009819   |  0.02555  |  0.98  |       |\n",
      "|        **ot1:ot2:agree-0.5:data0.5**        |  0.0008597  |   0.02611    |  0.03293  |  0.97  |       |\n",
      "|       **ot1:ot2:viewtype0.5:data0.5**       |   0.05826   |   0.01776    |   3.28    | 0.001  |  **   |\n",
      "|    **ot1:agree-0.5:viewtype0.5:data0.5**    |   0.06182   |   0.03184    |   1.942   | 0.052  |   .   |\n",
      "|    **ot2:agree-0.5:viewtype0.5:data0.5**    |   0.05264   |   0.02572    |   2.047   | 0.041  |   *   |\n",
      "|  **ot1:ot2:agree-0.5:viewtype0.5:data0.5**  |  -0.05506   |   0.03256    |  -1.691   | 0.091  |   .   |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pander_lme(exploratory_model_baseline_allint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "refitting model(s) with ML (instead of REML)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Df</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>logLik</th><th scope=col>deviance</th><th scope=col>Chisq</th><th scope=col>Chi Df</th><th scope=col>Pr(&gt;Chisq)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>exploratory_model_baseline_twowayint</th><td>23                       </td><td>-1127827                 </td><td>-1127593                 </td><td>563936.3                 </td><td>-1127873                 </td><td>      NA                 </td><td>NA                       </td><td>                       NA</td></tr>\n",
       "\t<tr><th scope=row>exploratory_model_baseline_allint</th><td>39                       </td><td>-1127911                 </td><td>-1127515                 </td><td>563994.7                 </td><td>-1127989                 </td><td>116.8469                 </td><td>16                       </td><td>0.00000000000000002213207</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       "  & Df & AIC & BIC & logLik & deviance & Chisq & Chi Df & Pr(>Chisq)\\\\\n",
       "\\hline\n",
       "\texploratory\\_model\\_baseline\\_twowayint & 23                        & -1127827                  & -1127593                  & 563936.3                  & -1127873                  &       NA                  & NA                        &                        NA\\\\\n",
       "\texploratory\\_model\\_baseline\\_allint & 39                        & -1127911                  & -1127515                  & 563994.7                  & -1127989                  & 116.8469                  & 16                        & 0.00000000000000002213207\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Df | AIC | BIC | logLik | deviance | Chisq | Chi Df | Pr(>Chisq) | \n",
       "|---|---|\n",
       "| exploratory_model_baseline_twowayint | 23                        | -1127827                  | -1127593                  | 563936.3                  | -1127873                  |       NA                  | NA                        |                        NA | \n",
       "| exploratory_model_baseline_allint | 39                        | -1127911                  | -1127515                  | 563994.7                  | -1127989                  | 116.8469                  | 16                        | 0.00000000000000002213207 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                                     Df AIC      BIC      logLik   deviance\n",
       "exploratory_model_baseline_twowayint 23 -1127827 -1127593 563936.3 -1127873\n",
       "exploratory_model_baseline_allint    39 -1127911 -1127515 563994.7 -1127989\n",
       "                                     Chisq    Chi Df Pr(>Chisq)               \n",
       "exploratory_model_baseline_twowayint       NA NA                            NA\n",
       "exploratory_model_baseline_allint    116.8469 16     0.00000000000000002213207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anova(exploratory_model_baseline_twowayint,\n",
    "      exploratory_model_baseline_allint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the model that includes all possible interaction\n",
    "terms is significantly better able to capture the data\n",
    "than the model that includes only two-way interaction terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaze patterns -- that is, the ways in which people look at\n",
    "things in their environment over time -- can reveal essential\n",
    "information about attention and understanding during conversation.\n",
    "When analyzing gaze patterns that are only tied to perception and\n",
    "information processing and *not* social signaling (i.e., looking\n",
    "at images while listening to a monologue without the speaker in\n",
    "the room), previous research has shown listeners who have more similar \n",
    "(or more *coordinated*) gaze patterns with speakers better understand\n",
    "the monologues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment explores the degree to which the coupling of\n",
    "information-processing gaze can be affected by the broader\n",
    "context of the interaction. We designed the experiment to\n",
    "test specifically listeners' agreement or disagreement with\n",
    "the speaker, but we unexpectedly found that the data could\n",
    "shed light on broader social processes around sociopolitical\n",
    "issues -- namely, whether the issue has been largely settled\n",
    "in the social setting (i.e., \"dominant-view\" topics) or has \n",
    "two opposing views of similar popularity in that social \n",
    "setting (i.e., \"mixed-view\" topics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to our hypotheses, we found that gaze coupling *increased*\n",
    "when listeners disagreed with the speakers. When performing\n",
    "exploratory analyses of the unexpected social setting variable (i.e.,\n",
    "whether the topic was dominant-view or mixed-view), we found\n",
    "another intriguing effect: Not only did listeners in all mixed-view\n",
    "(or controversial) topics have greater gaze coordination with speakers,\n",
    "but listeners who *disagreed* with the speakers about controversial\n",
    "topics had the *highest* amount of gaze coordination -- *even though the\n",
    "listeners could not see what the speakers were seeing*. These coordination\n",
    "dynamics suggest that listeners may be trying to attend more to speakers\n",
    "who are providing controversial opinions or opinions that are different\n",
    "from their own; given that previous work has causally linked gaze\n",
    "coordination with understanding (Richardson & Dale, 2005), this may suggest\n",
    "that listeners are being more active in their attempts to take these\n",
    "speakers' perspectives and \"see the other side.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
